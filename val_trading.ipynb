{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/SWaGXFOfCKxPJFPgyF5J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaskar-sinha/Business-Analytics-Datasets/blob/main/val_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EecPK5ayijtv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import ta\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import logging\n",
        "import time\n",
        "from collections import deque, defaultdict\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.tsa.statespace.kalman_filter import KalmanFilter\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# =====================\n",
        "# Core Configuration\n",
        "# =====================\n",
        "CONFIG = {\n",
        "    'SYMBOL': \"^NSEI\",\n",
        "    'LIVE_TRADING': False,\n",
        "    'DATA_FEED': {\n",
        "        'SOURCE': 'yfinance',\n",
        "        'RESOLUTION': '1m',\n",
        "        'HISTORICAL_DAYS': 30\n",
        "    },\n",
        "    'RISK_PARAMS': {\n",
        "        'MAX_POSITION_SIZE': 1000000,  # 10 lakh INR\n",
        "        'DAILY_LOSS_LIMIT': 0.02,  # 2%\n",
        "        'POSITION_VOLATILITY_TARGET': 0.15\n",
        "    },\n",
        "    'MODELS': {\n",
        "        'LSTM': {\n",
        "            'LOOKBACK_WINDOW': 60,\n",
        "            'EPOCHS': 50,\n",
        "            'BATCH_SIZE': 32\n",
        "        },\n",
        "        'SENTIMENT': {\n",
        "            'NEWS_SOURCES': ['reuters', 'economic_times'],\n",
        "            'UPDATE_FREQUENCY': 300  # 5 minutes\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# =====================\n",
        "# Market Data Engine\n",
        "# =====================\n",
        "class MarketDataEngine:\n",
        "    def __init__(self):\n",
        "        self.historical_data = None\n",
        "        self.live_data = deque(maxlen=1000)\n",
        "        self.volatility = 0\n",
        "        self.last_update = None\n",
        "        self.sentiment_score = 0\n",
        "        self.ist = pytz.timezone('Asia/Kolkata')\n",
        "        self._initialize()\n",
        "\n",
        "    def _initialize(self):\n",
        "        \"\"\"Load historical data and initialize models\"\"\"\n",
        "        logger.info(\"Initializing market data engine\")\n",
        "        self._load_historical_data()\n",
        "        self._initialize_models()\n",
        "        self.last_sentiment_update = datetime.now(self.ist)\n",
        "\n",
        "    def _load_historical_data(self):\n",
        "        \"\"\"Load historical price and volume data\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(CONFIG['SYMBOL'])\n",
        "            self.historical_data = ticker.history(\n",
        "                period=f\"{CONFIG['DATA_FEED']['HISTORICAL_DAYS']}d\",\n",
        "                interval=CONFIG['DATA_FEED']['RESOLUTION']\n",
        "            )\n",
        "            self._calculate_volatility()\n",
        "            logger.info(f\"Loaded {len(self.historical_data)} data points\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Historical data load failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _calculate_volatility(self):\n",
        "        \"\"\"Calculate historical volatility\"\"\"\n",
        "        returns = np.log(self.historical_data['Close']).diff().dropna()\n",
        "        self.volatility = returns.std() * np.sqrt(252)  # Annualized\n",
        "        logger.info(f\"Historical volatility: {self.volatility:.4f}\")\n",
        "\n",
        "    def update_live_data(self, bid, ask, volume):\n",
        "        \"\"\"Process new tick data\"\"\"\n",
        "        timestamp = datetime.now(self.ist)\n",
        "        mid_price = (bid + ask) / 2\n",
        "        spread = ask - bid\n",
        "\n",
        "        tick_data = {\n",
        "            'timestamp': timestamp,\n",
        "            'bid': bid,\n",
        "            'ask': ask,\n",
        "            'mid': mid_price,\n",
        "            'volume': volume,\n",
        "            'spread': spread\n",
        "        }\n",
        "\n",
        "        self.live_data.append(tick_data)\n",
        "        self.last_update = timestamp\n",
        "\n",
        "        # Update volatility estimate\n",
        "        if len(self.live_data) > 10:\n",
        "            returns = np.log([x['mid'] for x in self.live_data])\n",
        "            self.volatility = np.std(returns) * np.sqrt(252)\n",
        "\n",
        "        # Update sentiment periodically\n",
        "        if (timestamp - self.last_sentiment_update).total_seconds() > CONFIG['MODELS']['SENTIMENT']['UPDATE_FREQUENCY']:\n",
        "            self._update_sentiment()\n",
        "            self.last_sentiment_update = timestamp\n",
        "\n",
        "    def _update_sentiment(self):\n",
        "        \"\"\"Fetch and analyze news sentiment\"\"\"\n",
        "        analyzer = SentimentIntensityAnalyzer()\n",
        "        scores = []\n",
        "\n",
        "        for source in CONFIG['MODELS']['SENTIMENT']['NEWS_SOURCES']:\n",
        "            try:\n",
        "                news_text = self._fetch_news(source)\n",
        "                if news_text:\n",
        "                    vs = analyzer.polarity_scores(news_text)\n",
        "                    scores.append(vs['compound'])\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Sentiment analysis failed for {source}: {str(e)}\")\n",
        "\n",
        "        if scores:\n",
        "            self.sentiment_score = np.mean(scores)\n",
        "            logger.info(f\"Updated sentiment score: {self.sentiment_score:.2f}\")\n",
        "\n",
        "    def _fetch_news(self, source):\n",
        "        \"\"\"Fetch latest news headlines\"\"\"\n",
        "        if source == 'reuters':\n",
        "            url = \"https://www.reuters.com/markets/asia\"\n",
        "        elif source == 'economic_times':\n",
        "            url = \"https://economictimes.indiatimes.com/markets/stocks/news\"\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, timeout=5)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            headlines = [h.text for h in soup.find_all('h3')[:5]]\n",
        "            return \" \".join(headlines)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"News fetch failed from {source}: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "# =====================\n",
        "# Advanced Alpha Models\n",
        "# =====================\n",
        "class AlphaModels:\n",
        "    def __init__(self, data_engine):\n",
        "        self.data = data_engine\n",
        "        self.models = {}\n",
        "        self.scalers = {}\n",
        "        self._initialize()\n",
        "\n",
        "    def _initialize(self):\n",
        "        \"\"\"Initialize all alpha models\"\"\"\n",
        "        logger.info(\"Initializing alpha models\")\n",
        "\n",
        "        # Technical model\n",
        "        self.models['technical'] = TechnicalModel()\n",
        "\n",
        "        # Machine learning models\n",
        "        self.models['random_forest'] = RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=5,\n",
        "            random_state=42\n",
        "        )\n",
        "        self.models['gradient_boosting'] = GradientBoostingClassifier(\n",
        "            n_estimators=50,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=3,\n",
        "            random_state=42\n",
        "        )\n",
        "        self.models['svm'] = SVC(\n",
        "            kernel='rbf',\n",
        "            probability=True,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # LSTM Model\n",
        "        self.models['lstm'] = self._build_lstm_model()\n",
        "\n",
        "        # Statistical models\n",
        "        self.models['kalman'] = KalmanFilter(\n",
        "            dim_z=1,\n",
        "            dim_x=2,\n",
        "            dim_u=0\n",
        "        )\n",
        "\n",
        "        # Sentiment model\n",
        "        self.models['sentiment'] = SentimentModel()\n",
        "\n",
        "        # Initialize scalers\n",
        "        self.scalers['price'] = StandardScaler()\n",
        "        self.scalers['volume'] = StandardScaler()\n",
        "\n",
        "    def _build_lstm_model(self):\n",
        "        \"\"\"Build and compile LSTM model\"\"\"\n",
        "        model = Sequential([\n",
        "            LSTM(50, return_sequences=True,\n",
        "                 input_shape=(CONFIG['MODELS']['LSTM']['LOOKBACK_WINDOW'], 5)),\n",
        "            LSTM(50),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def generate_signals(self):\n",
        "        \"\"\"Generate trading signals from all models\"\"\"\n",
        "        signals = {}\n",
        "\n",
        "        # Technical signals\n",
        "        signals['technical'] = self.models['technical'].generate(\n",
        "            list(self.data.live_data)\n",
        "        )\n",
        "\n",
        "        # Prepare ML features\n",
        "        X = self._prepare_features()\n",
        "\n",
        "        if len(X) >= CONFIG['MODELS']['LSTM']['LOOKBACK_WINDOW']:\n",
        "            # ML model predictions\n",
        "            for name in ['random_forest', 'gradient_boosting', 'svm']:\n",
        "                signals[name] = self.models[name].predict_proba(X)[:, 1]\n",
        "\n",
        "            # LSTM prediction\n",
        "            lstm_input = self._prepare_lstm_input(X)\n",
        "            signals['lstm'] = self.models['lstm'].predict(lstm_input)[0][0]\n",
        "\n",
        "        # Statistical signals\n",
        "        signals['kalman'] = self.models['kalman'].filter()[0]\n",
        "\n",
        "        # Sentiment signals\n",
        "        signals['sentiment'] = self.models['sentiment'].generate(\n",
        "            self.data.sentiment_score\n",
        "        )\n",
        "\n",
        "        return signals\n",
        "\n",
        "    def _prepare_features(self):\n",
        "        \"\"\"Prepare features for ML models\"\"\"\n",
        "        prices = np.array([x['mid'] for x in self.data.live_data])\n",
        "        volumes = np.array([x['volume'] for x in self.data.live_data])\n",
        "\n",
        "        # Create technical indicators\n",
        "        df = pd.DataFrame({\n",
        "            'price': prices,\n",
        "            'volume': volumes\n",
        "        })\n",
        "\n",
        "        # Add technical indicators\n",
        "        df['sma_10'] = ta.trend.sma_indicator(df['price'], window=10)\n",
        "        df['ema_10'] = ta.trend.ema_indicator(df['price'], window=10)\n",
        "        df['rsi'] = ta.momentum.rsi(df['price'], window=14)\n",
        "        df['macd'] = ta.trend.macd(df['price'])\n",
        "        df['bb_upper'] = ta.volatility.bollinger_hband(df['price'])\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        # Scale features\n",
        "        X_price = self.scalers['price'].fit_transform(df[['price', 'sma_10', 'ema_10']])\n",
        "        X_vol = self.scalers['volume'].fit_transform(df[['volume']].values.reshape(-1, 1))\n",
        "\n",
        "        return np.concatenate([X_price, X_vol, df[['rsi', 'macd', 'bb_upper']].values], axis=1)\n",
        "\n",
        "    def _prepare_lstm_input(self, X):\n",
        "        \"\"\"Prepare input data for LSTM model\"\"\"\n",
        "        lookback = CONFIG['MODELS']['LSTM']['LOOKBACK_WINDOW']\n",
        "\n",
        "        if len(X) < lookback:\n",
        "            return None\n",
        "\n",
        "        X_lstm = []\n",
        "        for i in range(len(X) - lookback):\n",
        "            X_lstm.append(X[i:i + lookback])\n",
        "\n",
        "        return np.array(X_lstm)\n",
        "\n",
        "# =====================\n",
        "# Trading Engine Core\n",
        "# =====================\n",
        "class TradingEngine:\n",
        "    def __init__(self):\n",
        "        self.data_engine = MarketDataEngine()\n",
        "        self.alpha_models = AlphaModels(self.data_engine)\n",
        "        self.position = 0\n",
        "        self.pnl = 0\n",
        "        self.daily_pnl = []\n",
        "        self.order_history = []\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Main trading loop\"\"\"\n",
        "        logger.info(\"Starting trading engine\")\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                if not self._market_open():\n",
        "                    self._sleep_until_open()\n",
        "                    continue\n",
        "\n",
        "                # Simulate market data update\n",
        "                if CONFIG['DATA_FEED']['SOURCE'] == 'yfinance':\n",
        "                    tick_data = self._fetch_yfinance_tick()\n",
        "                else:\n",
        "                    tick_data = self._simulate_tick()\n",
        "\n",
        "                self.data_engine.update_live_data(\n",
        "                    tick_data['bid'],\n",
        "                    tick_data['ask'],\n",
        "                    tick_data['volume']\n",
        "                )\n",
        "\n",
        "                # Generate alpha signals\n",
        "                signals = self.alpha_models.generate_signals()\n",
        "\n",
        "                # Execute trading logic\n",
        "                self._execute_strategy(signals)\n",
        "\n",
        "                # Sleep based on data frequency\n",
        "                time.sleep(60 if CONFIG['DATA_FEED']['RESOLUTION'] == '1m' else 1)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            logger.info(\"Shutting down trading engine\")\n",
        "\n",
        "    def _execute_strategy(self, signals):\n",
        "        \"\"\"Execute trading based on model signals\"\"\"\n",
        "        # Combine signals (example: simple weighted average)\n",
        "        combined_signal = 0\n",
        "        weights = {\n",
        "            'technical': 0.3,\n",
        "            'random_forest': 0.2,\n",
        "            'gradient_boosting': 0.2,\n",
        "            'lstm': 0.15,\n",
        "            'sentiment': 0.15\n",
        "        }\n",
        "\n",
        "        for model, weight in weights.items():\n",
        "            if model in signals:\n",
        "                combined_signal += signals[model] * weight\n",
        "\n",
        "        # Determine position sizing based on volatility\n",
        "        pos_size = self._calculate_position_size(combined_signal)\n",
        "\n",
        "        # Generate orders\n",
        "        if combined_signal > 0.6:  # Strong buy signal\n",
        "            self._send_order('BUY', pos_size)\n",
        "        elif combined_signal < 0.4:  # Strong sell signal\n",
        "            self._send_order('SELL', pos_size)\n",
        "        elif combined_signal < 0.6 and combined_signal > 0.4:\n",
        "            logger.info(\"Neutral signal - holding position\")\n",
        "\n",
        "    def _calculate_position_size(self, signal_strength):\n",
        "        \"\"\"Calculate position size based on volatility and risk limits\"\"\"\n",
        "        max_size = CONFIG['RISK_PARAMS']['MAX_POSITION_SIZE']\n",
        "        vol_target = CONFIG['RISK_PARAMS']['POSITION_VOLATILITY_TARGET']\n",
        "\n",
        "        # Dynamic sizing based on volatility and signal strength\n",
        "        size = min(\n",
        "            max_size * signal_strength,\n",
        "            max_size * (vol_target / (self.data_engine.volatility + 0.01))\n",
        "        )\n",
        "\n",
        "        return max(1, int(size))  # At least 1 unit\n",
        "\n",
        "    def _send_order(self, side, size):\n",
        "        \"\"\"Simulate order execution\"\"\"\n",
        "        last_tick = self.data_engine.live_data[-1]\n",
        "        price = last_tick['ask'] if side == 'BUY' else last_tick['bid']\n",
        "\n",
        "        # Record order\n",
        "        self.order_history.append({\n",
        "            'timestamp': datetime.now(self.data_engine.ist),\n",
        "            'side': side,\n",
        "            'size': size,\n",
        "            'price': price\n",
        "        })\n",
        "\n",
        "        # Update position and PnL\n",
        "        prev_pos = self.position\n",
        "        self.position += size if side == 'BUY' else -size\n",
        "\n",
        "        # Mark-to-market PnL\n",
        "        current_value = self.position * last_tick['mid']\n",
        "        self.pnl = current_value - sum(o['price'] * o['size'] for o in self.order_history)\n",
        "        self.daily_pnl.append(self.pnl)\n",
        "\n",
        "        logger.info(\n",
        "            f\"Executed {side} order: {size} @ {price:.2f} | \"\n",
        "            f\"Position: {self.position} | PnL: {self.pnl:.2f}\"\n",
        "        )\n",
        "\n",
        "    def _market_open(self):\n",
        "        \"\"\"Check if market is currently open\"\"\"\n",
        "        now = datetime.now(self.data_engine.ist)\n",
        "        weekday = now.weekday()\n",
        "\n",
        "        if weekday >= 5:  # Weekend\n",
        "            return False\n",
        "\n",
        "        market_open = now.replace(hour=9, minute=15, second=0)\n",
        "        market_close = now.replace(hour=15, minute=30, second=0)\n",
        "\n",
        "        return market_open <= now <= market_close\n",
        "\n",
        "    def _sleep_until_open(self):\n",
        "        \"\"\"Sleep until next market open\"\"\"\n",
        "        now = datetime.now(self.data_engine.ist)\n",
        "\n",
        "        if now.weekday() == 4:  # Friday\n",
        "            next_open = (now + timedelta(days=3)).replace(\n",
        "                hour=9, minute=10, second=0\n",
        "            )\n",
        "        else:\n",
        "            next_open = (now + timedelta(days=1)).replace(\n",
        "                hour=9, minute=10, second=0\n",
        "            )\n",
        "\n",
        "        sleep_secs = (next_open - now).total_seconds()\n",
        "        logger.info(f\"Market closed. Sleeping for {sleep_secs/3600:.2f} hours\")\n",
        "        time.sleep(sleep_secs)\n",
        "\n",
        "    def _simulate_tick(self):\n",
        "        \"\"\"Generate simulated market data\"\"\"\n",
        "        if not self.data_engine.historical_data.empty:\n",
        "            last_close = self.data_engine.historical_data['Close'].iloc[-1]\n",
        "        else:\n",
        "            last_close = 25000\n",
        "\n",
        "        # Random walk with drift\n",
        "        price_change = np.random.normal(0.02, 0.5)\n",
        "        new_price = last_close + price_change\n",
        "\n",
        "        return {\n",
        "            'bid': new_price - 0.5,\n",
        "            'ask': new_price + 0.5,\n",
        "            'volume': random.randint(100, 500)\n",
        "        }\n",
        "\n",
        "    def _fetch_yfinance_tick(self):\n",
        "        \"\"\"Fetch real-time data from yfinance\"\"\"\n",
        "        ticker = yf.Ticker(CONFIG['SYMBOL'])\n",
        "        hist = ticker.history(period=\"1d\", interval=\"1m\")\n",
        "\n",
        "        if hist.empty:\n",
        "            return self._simulate_tick()\n",
        "\n",
        "        last_row = hist.iloc[-1]\n",
        "        return {\n",
        "            'bid': last_row['Close'] - 0.5,\n",
        "            'ask': last_row['Close'] + 0.5,\n",
        "            'volume': last_row['Volume']\n",
        "        }\n",
        "\n",
        "# =====================\n",
        "# Support Classes\n",
        "# =====================\n",
        "class TechnicalModel:\n",
        "    \"\"\"Traditional technical analysis model\"\"\"\n",
        "    def generate(self, market_data):\n",
        "        if len(market_data) < 20:\n",
        "            return 0\n",
        "\n",
        "        closes = np.array([x['mid'] for x in market_data])\n",
        "\n",
        "        # RSI\n",
        "        rsi = ta.momentum.rsi(closes, window=14)\n",
        "\n",
        "        # MACD\n",
        "        macd = ta.trend.macd(closes)\n",
        "        macd_signal = ta.trend.macd_signal(closes)\n",
        "\n",
        "        # Bollinger Bands\n",
        "        bb = ta.volatility.BollingerBands(closes)\n",
        "\n",
        "        # Combine signals\n",
        "        signal = 0\n",
        "        if macd[-1] > macd_signal[-1]:\n",
        "            signal += 0.3\n",
        "        if rsi[-1] < 30:\n",
        "            signal += 0.2\n",
        "        elif rsi[-1] > 70:\n",
        "            signal -= 0.2\n",
        "        if closes[-1] < bb.bollinger_lband()[-1]:\n",
        "            signal += 0.5\n",
        "\n",
        "        return min(max(signal, -1), 1)  # Clip to [-1, 1] range\n",
        "\n",
        "class SentimentModel:\n",
        "    \"\"\"Market sentiment analysis model\"\"\"\n",
        "    def generate(self, score):\n",
        "        # Map sentiment score (-1 to 1) to trading signal (0 to 1)\n",
        "        return (score + 1) / 2\n",
        "\n",
        "# =====================\n",
        "# Main Execution\n",
        "# =====================\n",
        "if __name__ == \"__main__\":\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    engine = TradingEngine()\n",
        "    engine.run()"
      ]
    }
  ]
}